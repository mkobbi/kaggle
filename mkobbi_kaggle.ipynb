{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, ElasticNetCV, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "train = pd.read_csv('data/train.csv', sep=';')\n",
    "test = pd.read_csv('data/test.csv', sep=';', names=list(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [train, test]\n",
    "data = pd.concat(frames, axis=0)\n",
    "categorical_columns = list(data.select_dtypes(include=['object']))\n",
    "#print(categorical_columns)\n",
    "for col in categorical_columns:\n",
    "    #print(data[col].unique())\n",
    "    data[col] = data[col].astype('category')\n",
    "    data[col] = data[col].cat.codes\n",
    "data['y'] = data['y'].replace(to_replace=0, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(data['y'], return_counts=True)\n",
    "decompte = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,  -2.88624567e+02,  -2.23425435e+02,\n",
       "          6.44860694e+04],\n",
       "       [  1.00000000e+00,  -4.22250721e+02,   7.80051901e+02,\n",
       "         -3.29377478e+05],\n",
       "       [  1.00000000e+00,  -2.94421063e+02,  -2.24941020e+02,\n",
       "          6.62273744e+04],\n",
       "       ..., \n",
       "       [  1.00000000e+00,  -4.01790166e+02,   8.01567785e+02,\n",
       "         -3.22062053e+05],\n",
       "       [  1.00000000e+00,   1.46897483e+02,  -1.03558974e+02,\n",
       "         -1.52125526e+04],\n",
       "       [  1.00000000e+00,   5.13482520e+02,  -7.56774427e+00,\n",
       "         -3.88590440e+03]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2, svd_solver='full', whiten=False)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "data = data.sample(frac=1).groupby('y', sort=False).head(decompte[1])\n",
    "#poly_data = \n",
    "data.head(10)\n",
    "#X,y = pca.fit_transform(normalize(data[data.columns[:-1]].values)),data[data.columns[-1]].values\n",
    "X,y = pca.fit_transform(data[data.columns[:-1]].values),data[data.columns[-1]].values\n",
    "X_train, X_test = np.split(poly.fit_transform(X), [train.shape[0]])\n",
    "y_train, y_test = np.split(y, [train.shape[0]])\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "#param_grid = {}\n",
    "#clf = GridSearchCV(MLPClassifier('solver':'adam', 'activation':'relu'), cv=10, n_jobs=-1, param_grid=param_grid)\n",
    "#clf = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "#beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "#hidden_layer_sizes=(100,), learning_rate='invscaling',\n",
    "#learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "#nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "#shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
    "#verbose=False, warm_start=True)\n",
    "#clf = AdaBoostClassifier(n_estimators=300)\n",
    "#clf = BalancedBaggingClassifier(KNeighborsClassifier(n_neighbors=7, leaf_size=25),n_estimators=100)\n",
    "#param_grid = {'C':np.arange(0.44,0.445,0.0001)}\n",
    "#clf = GridSearchCV(SVC(kernel='poly',class_weight='balanced',tol=1e-4), cv=10, n_jobs=-1, param_grid=param_grid)\n",
    "#clf = BaggingClassifier(base_estimator=SVC(C=0.06875,kernel='rbf',class_weight='balanced',tol=1e-4), n_jobs=-1, n_estimators=100)\n",
    "#clf = BaggingClassifier(LogisticRegression(),n_jobs=-1)\n",
    "clf = LogisticRegression(C=0.07)\n",
    "#decompte = dict(zip(unique, counts))\n",
    "#clf = BalancedBaggingClassifier(AdaBoostClassifier(algorithm='SAMME', base_estimator=SVC(kernel='linear', tol=1e-4, C=3.5, class_weight='balanced', probability=True)), oob_score=True, replacement=True, bootstrap=True, verbose=0, max_samples = 2* dict(zip(unique, counts))[1], ratio = 'majority', n_jobs=-1, random_state=42)\n",
    "#clf = ElasticNetCV(cv = 10,normalize=True,tol=1e-5, eps=0.01, verbose=0, n_jobs=-1)\n",
    "#clf = BalancedBaggingClassifier(base_estimator=LogisticRegression(C=0.7, tol=0.00001, class_weight='balanced'), bootstrap=True, verbose=0, max_samples = 2* dict(zip(unique, counts))[1], ratio = 'majority', n_jobs=-1, random_state=42 )\n",
    "#clf = SGDClassifier(loss='hinge',penalty='elasticnet',shuffle=True, random_state=42, class_weight='balanced')\n",
    "#clf = RandomForestClassifier(class_weight='balanced', n_estimators=20,criterion='entropy', random_state=42)\n",
    "#clf = BernoulliRBM()\n",
    "#clf = MLPClassifier(random_state=42)\n",
    "#clf = AdaBoostClassifier(base_estimator=KNeighborsClassifier(), random_state=42)\n",
    "#clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_train, y_train_train)\n",
    "y_train_pred = clf.predict(X_train_test)\n",
    "#y_train_pred[y_train_pred<0] = -1.0\n",
    "#y_train_pred[y_train_pred>0] = 1.0\n",
    "#print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701492537313\n",
      "0.704174228675\n",
      "1.19402985075\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train_test,y_train_pred))\n",
    "print(roc_auc_score(y_train_test,y_train_pred))\n",
    "print(mean_squared_error(y_train_test,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-28d64e128952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mkobbi/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mkobbi/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    298\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mkobbi/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    429\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 431\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred[y_pred<0] = -1.0\n",
    "y_pred[y_pred>0] = 1.0\n",
    "y_pred = [int(i) for i in y_pred]\n",
    "result = np.c_[range(1,len(y_pred)+1), y_pred]\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['Id', 'prediction'])\n",
    "df_result['prediction'] = df_result['prediction'].replace(to_replace=-1, value=0)\n",
    "#df_result[]\n",
    "df_result.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
